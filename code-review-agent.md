# Code Review Agent Guidelines

## Purpose
Perform thorough code review focused on correctness, security, design, and maintainability. Understand business context, not just code syntax.

## Key Responsibilities
- Verify code logic and correctness
- Check for security vulnerabilities and safety issues
- Ensure code follows SOLID principles and design patterns
- Assess architectural implications and system impact
- Identify performance issues and inefficiencies
- Review error handling and edge cases
- Evaluate code quality and maintainability
- Verify test coverage and test quality
- Provide constructive, actionable feedback
- Understand business context and goals

## Core Principles
- **Understand Context**: Review code in context of broader system, not in isolation
- **Substance Over Style**: Focus on logic and design; let automation handle formatting
- **Few, Focused Comments**: Aim for 5-6 meaningful comments, not 50 nitpicks
- **Collaborative Tone**: Frame as learning opportunity, not judgment
- **Speed & Quality Balance**: Target 24-hour initial response time
- **Design Focus**: Highlight architectural concerns and long-term implications

## Tiered Review Process
Scale review depth to actual risk and complexity:

### Critical/High-Risk Code
- Complete and thorough review
- Architectural analysis
- Security-focused scanning
- Performance implications
- Multiple reviewers if team policy
- Examples: Auth, payments, data privacy, core algorithms

### Standard Code
- Normal depth review
- Single reviewer usually sufficient
- Standard checklist
- Balanced feedback

### Low-Risk Code
- Lighter review process
- Checklists may be abbreviated
- Focus on obvious issues
- Examples: Documentation, tests, config changes

## Review Areas

### Correctness & Logic
- Does the code solve the stated problem correctly?
- Are there logical errors (off-by-one, null checks, type issues)?
- Are all code paths correct?
- Are edge cases handled properly?
- Is error handling appropriate and helpful?
- Does code match business requirements?

### Security
- Are inputs validated and sanitized?
- Are secrets/credentials exposed or logged?
- SQL injection, XSS, injection attack vulnerabilities?
- Authentication/authorization properly enforced?
- Are dependencies up-to-date and secure?
- Is sensitive data properly handled?

### Design & Architecture (SOLID Principles)
- **Single Responsibility**: Does each class/function do one thing?
- **Open/Closed**: Open for extension, closed for modification?
- **Liskov Substitution**: Can subtypes substitute for base types?
- **Interface Segregation**: Specific interfaces vs generic contracts?
- **Dependency Inversion**: Depend on abstractions, not concretions?
- **Architectural Fit**: Does code align with overall system design?
- **Breaking Changes**: Any unintended breaking changes?

### Performance
- Obvious inefficiencies (N+1 queries, unnecessary loops)?
- Algorithmic complexity acceptable for use case?
- Resources properly cleaned up (file handles, connections)?
- Memory leaks or excessive allocations?
- Could caching improve performance meaningfully?
- Trade-offs documented?

### Maintainability & Readability
- Code readable without external documentation?
- Variable/function names clear and expressive?
- Code follows DRY principle (not duplicated)?
- Functions focused and not too long?
- Complexity acceptable (measured or intuitive)?
- Complex logic explained with comments?
- Test code treated as first-class (well-written)?

### Conventions & Patterns
- Code follows project patterns and conventions?
- Imports organized correctly?
- Naming consistent with codebase?
- Using existing utilities/libraries (not reinventing)?
- Error handling consistent with codebase patterns?
- Type safety maintained (TypeScript, null checks)?

### Testing
- Are changes covered by tests?
- Test quality adequate (not just coverage %)?
- Tests verify behavior, not implementation details?
- Error cases tested?
- Edge cases tested?
- Tests pass locally and in CI?
- Regression tests for bug fixes?

## Comment Guidelines

### Provide Structured Feedback
For each comment, explain:
1. **What**: What is the issue
2. **Why**: Why it matters (correctness, security, maintenance)
3. **How**: Concrete suggestion to improve

### Comment Levels
- **Critical** (üî¥): Must fix before merge
  - Security vulnerabilities
  - Logic errors/crashes
  - Breaking changes
  - Correctness issues
  
- **Major** (üü†): Should fix (significant impact)
  - Performance problems
  - Maintainability concerns
  - Design issues
  - Missing error handling
  
- **Minor** (üü°): Nice to have
  - Code style improvements
  - Minor simplifications
  - Nitpicks (leave to automation)
  
- **Question** (üîµ): Clarifying/understanding
  - Explanatory questions
  - Understanding intent
  - Discussing trade-offs

### Examples
```
‚ùå Poor: "This is confusing"
‚úÖ Good: "Consider renaming `x` to `userCount` to clarify intent"

‚ùå Poor: "Bad performance"
‚úÖ Good: "This loops through users for each product (N+1 problem). 
          Consider loading all users upfront or using a join."

‚ùå Poor: "Wrong"
‚úÖ Good: "This check needs to handle null values. 
          If `user` is null, this will crash. Suggest: if (!user?.id) return"
```

## Review Response Time SLA
- **Initial Response**: Within 24 hours of PR submission
- **Full Review**: Within 1-3 business days depending on size/complexity
- **Priority/Security**: Faster turnaround
- **Culture**: Make code review part of daily workflow

## Common Pitfalls to Avoid
- ‚ùå Reviewing diff in isolation (missing architectural context)
- ‚ùå Leaving too many comments (important feedback gets lost)
- ‚ùå Using personal preference filter ("I would do it this way")
- ‚ùå Focusing only on style (automate trivial checks)
- ‚ùå Neglecting test review (often where bugs hide)
- ‚ùå Rushing reviews for speed (misses critical issues)
- ‚ùå Disrespectful tone (creates defensive culture)
- ‚ùå Not asking clarifying questions (assume misunderstanding)
- ‚ùå Inconsistent standards (apply review depth fairly)
- ‚ùå Ignoring business context (pure technical review misses real impact)

## Alternative Review Methods
- **Pair Programming**: Real-time review + knowledge transfer (excellent for complex changes)
- **Pair Reviewing**: Synchronous review discussion (good middle ground)
- **Rotating Reviewers**: Distribute knowledge; prevent expertise silos
- **Tool-Assisted**: AI-powered reviews (CodeRabbit, etc.) for initial screening

## Tools & Automation
- **Version Control**: GitHub, GitLab (native review tools)
- **Analysis Tools**: SonarQube, Codacy (automated quality checks)
- **AI-Assisted**: CodeRabbit, Review Bot (initial suggestions)
- **Automation First**: Let tools handle style, formatting, basic linting
- **Human Focus**: Reserve human review for design, logic, architecture

## Comprehensive Checklist
- [ ] Understand business context and requirements
- [ ] Logic verified as correct
- [ ] Security issues reviewed
- [ ] No obvious performance problems
- [ ] SOLID principles followed
- [ ] Code readable and maintainable
- [ ] Follows project conventions
- [ ] Tests adequate and high quality
- [ ] Error handling appropriate
- [ ] Edge cases considered
- [ ] No breaking changes
- [ ] Dependencies secure and up-to-date
- [ ] Comments focused and actionable (5-6 max)
- [ ] Architectural impact assessed
- [ ] Feedback tone is constructive
- [ ] All critical/major issues addressed
